name: PROD Deploy

on:
  workflow_dispatch:
    inputs:
      ref:
        description: "Git ref to deploy (branch/tag/sha)"
        required: true
        default: "main"

jobs:
  deploy:
    runs-on: [self-hosted, stage]
    env:
      PROD_LLM_BASE_URL: ${{ secrets.PROD_LLM_BASE_URL }}
      PROD_LLM_API_KEY: ${{ secrets.PROD_LLM_API_KEY }}
      PROD_LLM_MODEL: ${{ vars.PROD_LLM_MODEL }}
      NLY_ENV: prod
      LLM_PROVIDER: openai_compat
      LLM_REQUIRE_KEY: "true"

    steps:
      - name: Deploy from ~/app (git pull + compose up)
        shell: bash
        run: |
          set -euo pipefail

          APP_DIR="$HOME/app"
          REPO_URL="https://github.com/eberhardred42-hub/nayti-lyudey-mvp.git"

          if [ ! -d "$APP_DIR/.git" ]; then
            mkdir -p "$APP_DIR"
            git clone "$REPO_URL" "$APP_DIR"
          fi

          cd "$APP_DIR"
          git fetch --all
          git fetch --tags

          if [ "${{ inputs.ref }}" = "main" ]; then
            git reset --hard origin/main
          else
            git checkout --detach "${{ inputs.ref }}"
            git reset --hard "${{ inputs.ref }}"
          fi

          export FRONT_HOST_PORT=3000
          export API_HOST_PORT=8000
          export ML_HOST_PORT=8001
          export RENDER_HOST_PORT=8002
          export MINIO_HOST_PORT=9000
          export MINIO_CONSOLE_HOST_PORT=9001
          export DB_HOST_PORT=5432
          export REDIS_HOST_PORT=6379
          export S3_PRESIGN_ENDPOINT=${S3_PRESIGN_ENDPOINT:-http://localhost:9000}

          # Deterministic runtime env
          # - write to .env.runtime (requested)
          # - also copy to .env so docker compose always picks it up
          RUNTIME_ENV_FILE="$APP_DIR/.env.runtime"

          if [ -z "${PROD_LLM_API_KEY:-}" ]; then
            echo "ERROR: PROD_LLM_API_KEY is not set" >&2
            exit 1
          fi
          if [ -z "${PROD_LLM_BASE_URL:-}" ]; then
            echo "ERROR: PROD_LLM_BASE_URL is not set" >&2
            exit 1
          fi
          umask 077
          {
            printf '%s\n' "NLY_ENV=prod"
            printf '%s\n' "LLM_PROVIDER=openai_compat"
            printf '%s\n' "LLM_REQUIRE_KEY=true"
            printf '%s\n' "PROD_LLM_BASE_URL=${PROD_LLM_BASE_URL}"
            printf '%s\n' "PROD_LLM_MODEL=${PROD_LLM_MODEL:-gpt-4o-mini}"
            printf '%s\n' "PROD_LLM_API_KEY=${PROD_LLM_API_KEY}"
          } >"$RUNTIME_ENV_FILE"
          chmod 600 "$RUNTIME_ENV_FILE" || true

          cp "$RUNTIME_ENV_FILE" "$APP_DIR/.env"
          chmod 600 "$APP_DIR/.env" || true

          echo "== runtime env written: $RUNTIME_ENV_FILE (redacted) =="
          sed -E 's/(PROD_LLM_API_KEY=).+/\1***REDACTED***/' "$RUNTIME_ENV_FILE" | sed -n '1,30p'

          docker compose -p prod -f infra/docker-compose.yml up -d --build --force-recreate

      - name: Ensure caddy is running (host network)
        shell: bash
        run: |
          set -euo pipefail
          APP_DIR="$HOME/app"

          if docker ps -a --format '{{.Names}}' | grep -qx 'caddy'; then
            mode="$(docker inspect -f '{{.HostConfig.NetworkMode}}' caddy 2>/dev/null || true)"
            caddyfile_src="$(docker inspect -f '{{ range .Mounts }}{{ if eq .Destination "/etc/caddy/Caddyfile" }}{{ .Source }}{{ end }}{{ end }}' caddy 2>/dev/null || true)"
            if [ "$mode" != "host" ] || [ "$caddyfile_src" != "$APP_DIR/Caddyfile" ]; then
              echo "Recreating caddy (mode=$mode, Caddyfile mount=$caddyfile_src)"
              docker rm -f caddy || true
            fi
          fi

          if ! docker ps -a --format '{{.Names}}' | grep -qx 'caddy'; then
            docker run -d --name caddy --restart unless-stopped --network host \
              -v "$APP_DIR/Caddyfile:/etc/caddy/Caddyfile" \
              -v caddy_data:/data -v caddy_config:/config caddy:2
          else
            docker restart caddy
          fi

      - name: Smoke checks
        shell: bash
        run: |
          set -euo pipefail
          curl -fsS https://naitilyudei.ru/ >/dev/null
          curl -fsS https://naitilyudei.ru/api/docs >/dev/null
          cd "$HOME/app"
          docker compose -p prod -f infra/docker-compose.yml ps

      - name: Logs (only if failed)
        if: failure()
        shell: bash
        run: |
          cd "$HOME/app"
          docker logs --tail=200 caddy || true
          docker compose -p prod -f infra/docker-compose.yml logs --no-color --tail=200 || true
